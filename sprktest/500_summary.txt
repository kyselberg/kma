================================================================================
АНАЛІЗ ЛОГІВ ВИКОНАННЯ: МНОЖЕННЯ МАТРИЦЬ 500x500 ЧЕРЕЗ PYSPARK
================================================================================

КОНТЕКСТ ПРОЄКТУ
----------------
Проєкт реалізує розподілене множення великих матриць за допомогою Apache Spark
на Docker кластері. Архітектура включає:
- spark-master: головний вузол кластеру (порт 8080 для UI, 7077 для Spark)
- spark-worker: воркер-вузол для виконання обчислень (4 ядра, 8GB RAM)
- spark-client: контейнер, який запускає Spark-додаток для множення матриць

================================================================================
✅ УСПІШНІ РЕЗУЛЬТАТИ ТА ДОСЯГНЕННЯ
================================================================================

1. УСПІШНА ІНІЦІАЛІЗАЦІЯ КЛАСТЕРУ
   -----------------------------
   ✅ Docker Compose успішно запустив всі 3 контейнери
   ✅ Збірка образу spark-client виконалася швидко (0.1s, використано кеш)
   ✅ Мережа sprktest_default створена успішно
   ✅ Всі контейнери запущені без помилок

2. SPARK MASTER ЗАПУЩЕНО КОРЕКТНО
   ------------------------------
   ✅ Spark версія: 3.4.0
   ✅ Master запущено на spark://172.28.0.2:7077
   ✅ Web UI доступний на http://spark-master:8080
   ✅ Статус: ALIVE (Master обрано лідером)
   ✅ Успішно зареєстровано додаток MatrixMultiplication з ID app-20251105200834-0000

3. SPARK WORKER ПІДКЛЮЧЕНО ТА ПРАЦЮЄ
   ----------------------------------
   ✅ Worker успішно підключився до Master: spark://spark-master:7077
   ✅ Ресурси: 4 cores, 8.0 GiB RAM
   ✅ Worker UI доступний на http://spark-worker:8081
   ✅ NumPy 2.2.6 встановлено успішно (14.3 MB завантажено за 9.6 MB/s)
   ✅ Worker зареєстровано в Master через 2 секунди після запуску

4. SPARK CLIENT (ДОДАТОК) ВИКОНАВСЯ УСПІШНО
   ----------------------------------------
   ✅ Application ID: app-20251105200834-0000
   ✅ Application name: MatrixMultiplication
   ✅ Підключено до кластеру успішно
   ✅ SparkContext створено без помилок
   ✅ Spark UI доступний на порту 4040
   ✅ Executor успішно запущено на worker (4 cores, 7.0 GiB RAM)

5. ГЕНЕРАЦІЯ МАТРИЦЬ
   -----------------
   ✅ Матриці згенеровано успішно: розмір 500x500
   ✅ Матриця A: seed=42, значення 0-1000, тип int32
     - Мінімум: 0, Максимум: 1000
     - Середнє: 499.93, Стандартне відхилення: 288.90
   ✅ Матриця B: seed=123, значення 0-1000, тип int32
     - Мінімум: 0, Максимум: 1000
     - Середнє: 500.24, Стандартне відхилення: 289.13
   ✅ Статистика показує коректне розподілення значень

6. БЛОЧНЕ МНОЖЕННЯ ЧЕРЕЗ SPARK
   ----------------------------
   ✅ Broadcast механізм працює коректно:
     - Broadcast A: 704.1 KiB в пам'яті
     - Broadcast B: 704.3 KiB в пам'яті
   ✅ Блоки створено: 1 блок для A, 1 блок для B
   ✅ Task виконано успішно на executor 0 (worker 172.28.0.3)
   ✅ Використання пам'яті оптимальне (4.0 GiB доступно після broadcast)

7. ШВИДКІСТЬ ВИКОНАННЯ
   --------------------
   ✅ Загальний час множення: 3.78 секунд
   ✅ Spark job виконано за: 3.470897 секунд
   ✅ Task виконано за: 843 мілісекунд на executor
   ✅ Швидкість виконання дуже хороша для матриці 500x500

8. РЕЗУЛЬТАТИ ОБЧИСЛЕНЬ
   --------------------
   ✅ Результуюча матриця створена: розмір (500, 500), тип int32
   ✅ Статистика результату:
     - Мінімум: 104,089,123
     - Максимум: 146,617,737
     - Середнє: 125,038,679.16
     - Стандартне відхилення: 4,771,929.13
   ✅ Результати мають очікуваний діапазон значень для множення матриць

9. ЗБЕРЕЖЕННЯ РЕЗУЛЬТАТІВ
   -----------------------
   ✅ Матриці успішно збережено у /opt/spark/data/:
     - matrix_a.npy: 0.95 MB
     - matrix_b.npy: 0.95 MB
     - result.npy: 0.95 MB
   ✅ Всі файли створено без помилок

10. КОРЕКТНЕ ЗАВЕРШЕННЯ РОБОТИ
    ---------------------------
    ✅ SparkContext успішно зупинено з exitCode 0
    ✅ Executor завершено коректно
    ✅ Всі тимчасові директорії очищено
    ✅ Контейнер spark-client завершив роботу без помилок
    ✅ Немає помилок у логах під час shutdown

11. АРХІТЕКТУРА ТА ІНФРАСТРУКТУРА
    -------------------------------
    ✅ Мережева комунікація працює коректно між контейнерами
    ✅ BlockManager працює правильно (broadcast, replication)
    ✅ DAGScheduler виконав job без проблем
    ✅ TaskScheduler розподілив завдання коректно

================================================================================
❌ ПРОБЛЕМИ ТА НЕВІДПОВІДНОСТІ
================================================================================

1. КРИТИЧНА ПРОБЛЕМА: НЕКОРЕКТНІ РЕЗУЛЬТАТИ МНОЖЕННЯ
   -------------------------------------------------
   ❌ Результати множення НЕ збігаються з очікуваними!

   Перевірка на невеликій частині (100x100):
   - Точне збігання: False
   - Максимальна різниця: 115,161,401
   - Середня різниця: 100,383,271.65

   ⚠️  Це означає, що алгоритм блочного множення матриць працює НЕКОРЕКТНО!
   Результати значно відрізняються від правильних (обчислених через NumPy).

   Можливі причини:
   - Помилка в логіці функції multiply_block_indices()
   - Неправильне витягування блоків з матриць A та B
   - Помилка в збиранні результатів блоків у фінальну матрицю
   - Можлива проблема з індексацією при об'єднанні блоків


3. ПОПЕРЕДЖЕННЯ ПРО РЕСУРСИ
   -------------------------
   ⚠️  Spark Master зафіксував попередження:
   "App app-20251105200834-0000 requires more resource than any of Workers
    could have."

   Конфігурація додатку:
   - spark.executor.memory: 7g
   - spark.executor.cores: 4

   Ресурси Worker:
   - SPARK_WORKER_MEMORY: 8g
   - SPARK_WORKER_CORES: 4

   Хоча це не завадило виконанню, це може призвести до проблем на великих
   навантаженнях або при додаванні більше воркерів.


================================================================================
ВИСНОВКИ
================================================================================

✅ СИЛЬНІ СТОРОНИ:
   - Кластер Spark працює стабільно та коректно
   - Інфраструктура Docker налаштована правильно
   - Швидкість виконання хороша
   - Збереження результатів працює
   - Всі компоненти комунікують правильно



У цьому проєкті я порівняв ефективність блочного множення великих матриць через PySpark на Docker кластері. Хотів подивитися, як масштабується алгоритм на різних розмірах матриць – від середніх (500x500) до дуже великих (5000x5000), де саме виникають вузькі місця в обчисленнях, і чи правильно працює блочний підхід з розподіленням через Spark RDD. Порівнював три розміри матриць: 500x500, 1000x1000 та 5000x5000, щоб зрозуміти, як змінюється час виконання, використання пам’яті, кількість задач і, найголовніше, чи зберігається коректність результатів при збільшенні складності.

Мої цілі: виміряти продуктивність на різних розмірах матриць, оцінити ефективність broadcast-механізму для великих даних, з’ясувати, чи працює паралелізація через Spark RDD коректно, і знайти проблеми в алгоритмі, якщо вони є. Особливо цікавило, як буде працювати блочний підхід, коли матриці розбиваються на частини і обчислюються на різних вузлах кластеру.

Оточення підняв через Docker Compose: три контейнери – spark-master (головний вузол кластеру на портах 8080 для UI та 7077 для Spark), spark-worker (воркер-вузол з 4 ядрами та 8GB RAM) і spark-client (контейнер, який запускає Spark-додаток для множення матриць). Master та worker базуються на образі apache/spark-py:latest, а client має власний Dockerfile, де встановлено NumPy 2.2.6. Ресурси worker: 8GB пам’яті, 4 ядра; client має 6GB пам’яті та 2 ядра. Spark-додаток налаштований з executor пам’яттю 7GB, 4 ядрами, driver пам’яттю 8GB, maxResultSize 6GB, serializer Kryo. Це дозволило порівнювати результат саме через різницю в розмірах матриць та кількості блоків, а не через різну конфігурацію кластеру.

Алгоритм блочного множення працює так: обидві матриці A та B передаються через Spark broadcast-механізм (ефективніше для великих матриць, ніж передача через замикання). Матриці розбиваються на блоки розміром 1000x1000 (параметр block_size). Для кожного блоку результату C[block_i, block_j] створюється пара індексів (block_i, block_j), яка визначає, які рядки матриці A та які стовпці матриці B потрібно перемножити. Для блоку результату C[row_start:row_end, col_start:col_end] беруться рядки row_start:row_end з A (усі стовпці) та стовпці col_start:col_end з B (усі рядки), після чого виконується множення через NumPy np.dot. Отримані блоки збираються в RDD, виконуються через map, після чого збираються через collect() і вручну розміщуються у фінальну матрицю за індексами. Це дозволяє паралелізувати обчислення блоків, особливо для великих матриць, де кількість блоків може бути значною.

Для матриці 500x500 створюється 1 блок для A та 1 блок для B (всього 1 задача), що означає, що вся матриця обчислюється в одному task. Broadcast займає 704.1 KiB для A та 704.3 KiB для B. Загальний час множення становить 3.78 секунд, з яких Spark job виконується за 3.47 секунд, а task на executor – 843 мілісекунд. Результат зберігається у файли розміром 0.95 MB кожен. Перевірка коректності на невеликій частині (100x100) показує критичну проблему: результати НЕ збігаються з очікуваними. Точне збігання: False, максимальна різниця: 115,161,401, середня різниця: 100,383,271.65. Це означає, що алгоритм працює некоректно навіть для найменшої матриці.

Для матриці 1000x1000 також створюється 1 блок для A та 1 блок для B (всього 1 задача), оскільки розмір матриці все ще менший за block_size 1000. Broadcast збільшується до 2.7 MiB для обох матриць. Загальний час множення становить 5.06 секунд, з яких Spark job виконується за 4.71 секунд, а task на executor – 1751 мілісекунд. Порівняно з 500x500, час збільшився лише на 34% при збільшенні матриці у 4 рази (що є хорошим результатом з точки зору масштабування). Розмір файлів збільшився до 3.81 MB кожен. Проблема з коректністю зростає: максимальна різниця становить 249 мільйонів, середня різниця – 225 мільйонів. Це вказує на те, що помилка систематична і збільшується пропорційно розміру матриці.

Для матриці 5000x5000 картина кардинально змінюється. Створюється 5 блоків для A та 5 блоків для B (всього 25 задач). Broadcast розбивається на фрагменти: матриця A передається як 17 pieces по 4 MiB плюс останній 732.7 KiB (загалом ~68.7 MiB), матриця B – аналогічно (~68.7 MiB). Це демонструє, що Spark автоматично розбиває великі broadcast-змінні на частини для ефективної передачі. Загальний час множення становить 332.21 секунд (~5.5 хвилин), з яких Spark job виконується за 316.51 секунд (~5.3 хвилин), а ResultStage – за 329.16 секунд. Середній час виконання task: ~44-50 секунд, найшвидший task виконався за 42.4 секунд, найповільніший – за 58.4 секунд. Tasks виконуються паралельно через 4 ядра executor, що дозволяє ефективно використовувати ресурси. Ефективність: ~13.3 секунд на блок (1000x1000), що є досить хорошим результатом. Розмір файлів збільшився до 95.37 MB кожен. Проблема з коректністю стає критичною: максимальна різниця становить 1,281 мільярд, середня різниця – 1,226 мільярд. Це вказує на експоненційне зростання помилки зі збільшенням кількості блоків.

Порівняння продуктивності показує такі тренди. Час виконання зростає експоненційно: 3.78s → 5.06s → 332.21s. Це пояснюється тим, що для 5000x5000 створюється 25 задач замість 1, і навіть при паралелізації через 4 ядра час виконання значно збільшується. Task час (середній) зростає лінійно: 843ms → 1751ms → ~45s. Кількість tasks зростає квадратично: 1 → 1 → 25. Розмір broadcast зростає лінійно: 704 KiB → 2.7 MiB → 68.7 MiB. Розмір файлів зростає квадратично: 0.95 MB → 3.81 MB → 95.37 MB. Найкритичніше – помилка коректності зростає експоненційно: максимальна різниця 115M → 249M → 1,281M, середня різниця 100M → 225M → 1,226M. Це вказує на систематичну помилку в алгоритмі, яка накопичується зі збільшенням кількості блоків.

Аналіз планів виконання та логів показує наступне. Для матриць 500x500 та 1000x1000 виконується одна задача, яка обчислює весь результат одразу. Broadcast працює ефективно, матриці передаються на executor, де виконується множення через NumPy. Для матриці 5000x5000 створюється 25 задач, які виконуються паралельно через 4 ядра. Broadcast автоматично розбивається на pieces для ефективної передачі великих матриць. Task results передаються назад на driver (по 3.8 MiB кожен блок), після чого збираються в фінальну матрицю. Паралелізація працює коректно – tasks виконуються одночасно, що дозволяє ефективно використовувати ресурси кластеру. Однак проблема коректності критична: результати не збігаються з очікуваними навіть для найменших матриць, а помилка зростає експоненційно зі збільшенням кількості блоків. Це вказує на систематичну помилку в логіці збирання блоків у фінальну матрицю або в самій функції множення блоків.

Підсумок: блочний підхід через Spark RDD демонструє хорошу масштабованість з точки зору продуктивності – час виконання зростає менш ніж експоненційно при збільшенні розміру матриці, broadcast-механізм ефективно працює з великими матрицями, автоматично розбиваючи їх на pieces, паралелізація через Spark працює коректно, tasks виконуються одночасно на доступних ядрах. Однак виявлена критична проблема з коректністю результатів: алгоритм працює некоректно навіть для найменших матриць, а помилка зростає експоненційно зі збільшенням кількості блоків. Це означає, що алгоритм потребує виправлення – ймовірно, проблема в логіці збирання блоків у фінальну матрицю або в самій функції множення блоків. Для практичного використання необхідно виправити алгоритм, щоб забезпечити коректність результатів на всіх розмірах матриць.
